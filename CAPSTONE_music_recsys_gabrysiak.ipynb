{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lauragabrysiak/mitx_applied_data_science/blob/main/CAPSTONE_music_recsys_gabrysiak.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyAjEw4OHmDb"
      },
      "source": [
        "# **Music Recommendation System**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Context:**\n",
        "\n",
        "With the advent of technology, societies have become more efficient with their lives. At the same time, however, individual human lives have also become more fast-paced and distracted, leaving little time to explore artistic pursuits. Also, technology has made significant advancements in the ability to coexist with art and general entertainment. It has in fact made it easier for humans with a shortage of time to find and consume good content.\n",
        "Almost every internet-based company's revenue relies on the time consumers spend on its platform. These companies need to be able to figure out what kind of content is needed in order to increase customer time spent and make their experience better. Therefore, one of the key challenges for these companies is figuring out what kind of content their customers are most likely to consume. Spotify is one such audio content provider with a huge market base across the world. With the ever-increasing volume of songs becoming available on the Internet, searching for songs of interest has become a tedious task in itself.\n",
        "However, Spotify has grown significantly in the market because of its ability to recommend the 'best' next song to each and every customer based on a huge preference database gathered over time - millions of customers and billions of songs. This is done by using smart recommendation systems that can recommend songs based on users' likes/dislikes.\n",
        "\n",
        "Source: https://olympus.mygreatlearning.com/courses/87799/files/7049375?module_item_id=3469914\n",
        "\n",
        "**Why is this problem important to solve?**\n",
        "\n",
        "Competitive advantage by user experience and insights + data as a product.\n",
        "\n"
      ],
      "metadata": {
        "id": "CwYNsV578acL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVUiyhYTHS1t"
      },
      "source": [
        "## **Data Dictionary**\n",
        "\n",
        "The core data is the Taste Profile Subset released by the Echo Nest as part of the Million Song Dataset. There are two files in this dataset. The first file contains the details about the song id, titles, release, artist name, and the year of release. The second file contains the user id, song id, and the play count of users.\n",
        "\n",
        "## S1: song_data\n",
        "*   song_id - A unique id given to every song\n",
        "*   title - Title of the song\n",
        "*   Release - Name of the released album\n",
        "*   Artist_name - Name of the artist\n",
        "*   year - Year of release\n",
        "\n",
        "## S2: count_data\n",
        "*   user _id - A unique id given to the user\n",
        "*   song_id - A unique id given to the song\n",
        "*   play_count - Number of times the song was played\n",
        "\n",
        "## **Data Source**\n",
        "http://millionsongdataset.com/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnY1ylHnRf-x"
      },
      "source": [
        "## Data Understanding\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRJtXkTrHxMQ"
      },
      "source": [
        "### **Importing Libraries and the Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXZZ6Ma0ahcc"
      },
      "source": [
        "#### Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SRzOPXI2Efn",
        "outputId": "b002bbd0-86c9-44c3-d800-c7295979b559"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "# Mounting the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ch6RGxQ_alkL"
      },
      "source": [
        "#### Install Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "rncMR5r3SN0e",
        "outputId": "82419aed-f546-4c2c-a631-f7d78bad0c9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting surprise\n",
            "  Downloading surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
            "Collecting scikit-surprise (from surprise)\n",
            "  Downloading scikit-surprise-1.1.3.tar.gz (771 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m772.0/772.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.11.4)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.3-cp310-cp310-linux_x86_64.whl size=3163757 sha256=1be42778bc5d2f42180151d6b9835e50fde7122f07c6568eb4f1de534700c1ec\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/ca/a8/4e28def53797fdc4363ca4af740db15a9c2f1595ebc51fb445\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise, surprise\n",
            "Successfully installed scikit-surprise-1.1.3 surprise-0.1\n"
          ]
        }
      ],
      "source": [
        "# Installing surprise library\n",
        "!pip install surprise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iG6ugEn3buv1",
        "outputId": "56e5c044-d643-4dd8-e451-905035ecbd65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.5.1)\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Installing collected packages: matplotlib\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.5.1\n",
            "    Uninstalling matplotlib-3.5.1:\n",
            "      Successfully uninstalled matplotlib-3.5.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "plotnine 0.12.4 requires statsmodels>=0.14.0, but you have statsmodels 0.13.5 which is incompatible.\n",
            "ydata-profiling 4.0.0 requires matplotlib<3.7,>=3.2, but you have matplotlib 3.8.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed matplotlib-3.8.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ydata-profiling[notebook]==4.0.0 in /usr/local/lib/python3.10/dist-packages (4.0.0)\n",
            "Collecting matplotlib==3.5.1\n",
            "  Using cached matplotlib-3.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.9 MB)\n",
            "Requirement already satisfied: scipy<1.10,>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling[notebook]==4.0.0) (1.9.3)\n",
            "Requirement already satisfied: pandas!=1.4.0,<1.6,>1.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling[notebook]==4.0.0) (1.5.3)\n",
            "Requirement already satisfied: pydantic<1.11,>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling[notebook]==4.0.0) (1.10.13)\n",
            "Requirement already satisfied: PyYAML<6.1,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling[notebook]==4.0.0) (6.0.1)\n",
            "Requirement already satisfied: jinja2<3.2,>=2.11.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling[notebook]==4.0.0) (3.1.2)\n",
            "Requirement already satisfied: visions[type_image_path]==0.7.5 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling[notebook]==4.0.0) (0.7.5)\n",
            "Requirement already satisfied: numpy<1.24,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling[notebook]==4.0.0) (1.23.5)\n",
            "Requirement already satisfied: htmlmin==0.1.12 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling[notebook]==4.0.0) (0.1.12)\n",
            "Requirement already satisfied: phik<0.13,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling[notebook]==4.0.0) (0.12.3)\n",
            "Requirement already satisfied: requests<2.29,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling[notebook]==4.0.0) (2.28.2)\n",
            "Requirement already satisfied: tqdm<4.65,>=4.48.2 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling[notebook]==4.0.0) (4.64.1)\n",
            "Requirement already satisfied: seaborn<0.13,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling[notebook]==4.0.0) (0.12.2)\n",
            "Requirement already satisfied: multimethod<1.10,>=1.4 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling[notebook]==4.0.0) (1.9.1)\n",
            "Requirement already satisfied: statsmodels<0.14,>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling[notebook]==4.0.0) (0.13.5)\n",
            "Requirement already satisfied: typeguard<2.14,>=2.13.2 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling[notebook]==4.0.0) (2.13.3)\n",
            "Requirement already satisfied: jupyter-client>=5.3.4 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling[notebook]==4.0.0) (6.1.12)\n",
            "Requirement already satisfied: jupyter-core>=4.6.3 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling[notebook]==4.0.0) (5.5.0)\n",
            "Requirement already satisfied: ipywidgets>=7.5.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling[notebook]==4.0.0) (7.7.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.1) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.1) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.1) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.1) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.1) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.1) (2.8.2)\n",
            "Requirement already satisfied: attrs>=19.3.0 in /usr/local/lib/python3.10/dist-packages (from visions[type_image_path]==0.7.5->ydata-profiling[notebook]==4.0.0) (23.1.0)\n",
            "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.10/dist-packages (from visions[type_image_path]==0.7.5->ydata-profiling[notebook]==4.0.0) (3.2.1)\n",
            "Requirement already satisfied: tangled-up-in-unicode>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from visions[type_image_path]==0.7.5->ydata-profiling[notebook]==4.0.0) (0.2.0)\n",
            "Requirement already satisfied: imagehash in /usr/local/lib/python3.10/dist-packages (from visions[type_image_path]==0.7.5->ydata-profiling[notebook]==4.0.0) (4.3.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (3.6.6)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (3.0.9)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<3.2,>=2.11.1->ydata-profiling[notebook]==4.0.0) (2.1.3)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter-client>=5.3.4->ydata-profiling[notebook]==4.0.0) (23.2.1)\n",
            "Requirement already satisfied: tornado>=4.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client>=5.3.4->ydata-profiling[notebook]==4.0.0) (6.3.2)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.3->ydata-profiling[notebook]==4.0.0) (4.0.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=1.4.0,<1.6,>1.1->ydata-profiling[notebook]==4.0.0) (2023.3.post1)\n",
            "Requirement already satisfied: joblib>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from phik<0.13,>=0.11.1->ydata-profiling[notebook]==4.0.0) (1.3.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<1.11,>=1.8.1->ydata-profiling[notebook]==4.0.0) (4.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib==3.5.1) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<2.29,>=2.24.0->ydata-profiling[notebook]==4.0.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<2.29,>=2.24.0->ydata-profiling[notebook]==4.0.0) (3.6)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<2.29,>=2.24.0->ydata-profiling[notebook]==4.0.0) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<2.29,>=2.24.0->ydata-profiling[notebook]==4.0.0) (2023.11.17)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels<0.14,>=0.13.2->ydata-profiling[notebook]==4.0.0) (0.5.3)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (3.0.41)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (4.9.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (6.5.5)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.10/dist-packages (from imagehash->visions[type_image_path]==0.7.5->ydata-profiling[notebook]==4.0.0) (1.5.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (0.8.3)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (23.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (5.9.2)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (1.5.8)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (0.18.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (0.19.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (1.0.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (0.2.12)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (1.24.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (0.2.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (4.9.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (4.11.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (0.3.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (0.9.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (1.5.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (1.2.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (2.19.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (4.19.2)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (21.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (2023.11.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (0.31.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (0.13.2)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (1.6.4)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (0.5.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (1.2.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->ydata-profiling[notebook]==4.0.0) (2.21)\n",
            "Installing collected packages: matplotlib\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.8.2\n",
            "    Uninstalling matplotlib-3.8.2:\n",
            "      Successfully uninstalled matplotlib-3.8.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "plotnine 0.12.4 requires matplotlib>=3.6.0, but you have matplotlib 3.5.1 which is incompatible.\n",
            "plotnine 0.12.4 requires statsmodels>=0.14.0, but you have statsmodels 0.13.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed matplotlib-3.5.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Installing Pandas Profile\n",
        "!pip install --upgrade matplotlib\n",
        "!pip install -U ydata-profiling[notebook]==4.0.0 matplotlib==3.5.1  # last matplotlib is 3.8.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PoqDjgrRbs7C"
      },
      "outputs": [],
      "source": [
        "# Installing Pandas Profile\n",
        "!pip install spotipy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxNVorA8ao2I"
      },
      "source": [
        "#### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "R4YvKrpzId3K"
      },
      "outputs": [],
      "source": [
        "import warnings                                 # Used to ignore the warning given as output of the code\n",
        "warnings.filterwarnings('ignore')\n",
        "from collections import defaultdict             # A dictionary output that does not raise a key error\n",
        "\n",
        "import numpy as np                              # Basic libraries of python for numeric and dataframe computations\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt                 # data visualization\n",
        "import seaborn as sns                           # data visualization advanced\n",
        "\n",
        "from sklearn.metrics import mean_squared_error  # A performance metrics in sklearn\n",
        "\n",
        "from ydata_profiling import ProfileReport       # Adding pandas report\n",
        "from scipy.stats import pearsonr                # pearson correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "NlC7rAvKbzbl"
      },
      "outputs": [],
      "source": [
        "import spotipy\n",
        "from spotipy.oauth2 import SpotifyClientCredentials\n",
        "from spotipy import SpotifyException"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUGKX140wf-S"
      },
      "source": [
        "### **Datasets**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBrgp6LPayFm"
      },
      "source": [
        "#### Import datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "si6ulhIYImck"
      },
      "outputs": [],
      "source": [
        "# Importing the datasets\n",
        "song_df = pd.read_csv('/content/sample_data/song_data.csv'\n",
        "                  , on_bad_lines='skip')                        # some of the lines had formatting issues. This can be solved with bad_lines = skip\n",
        "count_df = pd.read_csv('/content/sample_data/count_data.csv'\n",
        "                  , on_bad_lines='skip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "A7tGO-1aUGDt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7aebf3e1-a5ba-4470-b531-7df8ceb791e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Song Dataset: No of rows = 1000000 and No of columns = 5\n"
          ]
        }
      ],
      "source": [
        "rows, columns = song_df.shape\n",
        "print(\"Song Dataset: No of rows =\", rows, \"and No of columns =\", columns)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rows, columns = count_df.shape\n",
        "print(\"Count Dataset: No of rows =\", rows, \"and No of columns =\", columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTZ0MGFYX1mo",
        "outputId": "9671c744-00e3-4ff8-bded-6fa0eaf3826d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count Dataset: No of rows = 2000000 and No of columns = 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fIuqUJsgUMww",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3a2add6-caa2-400c-abbe-86aa78583d4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000000 entries, 0 to 999999\n",
            "Data columns (total 5 columns):\n",
            " #   Column       Non-Null Count    Dtype \n",
            "---  ------       --------------    ----- \n",
            " 0   song_id      1000000 non-null  object\n",
            " 1   title        999985 non-null   object\n",
            " 2   release      999995 non-null   object\n",
            " 3   artist_name  1000000 non-null  object\n",
            " 4   year         1000000 non-null  int64 \n",
            "dtypes: int64(1), object(4)\n",
            "memory usage: 38.1+ MB\n",
            "None\n",
            "\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2000000 entries, 0 to 1999999\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Dtype \n",
            "---  ------      ----- \n",
            " 0   Unnamed: 0  int64 \n",
            " 1   user_id     object\n",
            " 2   song_id     object\n",
            " 3   play_count  int64 \n",
            "dtypes: int64(2), object(2)\n",
            "memory usage: 61.0+ MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(song_df.info())   # there is some missing information (title (-15) /release (-5) )\n",
        "print(\"\\n\")\n",
        "print(count_df.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOW0Lr0qa5_j"
      },
      "source": [
        "#### Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12TKB2M7XyC6"
      },
      "source": [
        "#### S1) **Count dataset**\n",
        "\n",
        "Dataset of 2000000 x 3 variables. Includes the number of times that songs were played and by who (user). Includes the song_id as primary key for reference"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Data Preparation"
      ],
      "metadata": {
        "id": "PqlfpoYvXBWD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "z2cjh0-DVQkS"
      },
      "outputs": [],
      "source": [
        "count_df.columns = ['index','user_id', 'song_id', 'play_count']     # Adding column names\n",
        "count_df_copy = count_df .copy(deep = True)                         # backup copy\n",
        "count_df = count_df.drop('index', axis = 1)                         # Dropping index # Drop the column 'Unnamed: 0' // already done"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Data Univariate EDA"
      ],
      "metadata": {
        "id": "7jXYD0QyXQAq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GCLzBuYiXlPM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "abbeac37-a2b9-419d-f286-14a6e61cab96"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    user_id             song_id  play_count\n",
              "0  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOAKIMP12A8C130995           1\n",
              "1  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBBMDR12A8C13253B           2\n",
              "2  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBXHDL12A81C204C0           1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ca1d904f-add5-4bba-95f3-6c6ab5c33552\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>song_id</th>\n",
              "      <th>play_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
              "      <td>SOAKIMP12A8C130995</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
              "      <td>SOBBMDR12A8C13253B</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
              "      <td>SOBXHDL12A81C204C0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca1d904f-add5-4bba-95f3-6c6ab5c33552')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ca1d904f-add5-4bba-95f3-6c6ab5c33552 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ca1d904f-add5-4bba-95f3-6c6ab5c33552');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-92cecb20-ff65-4be7-8de8-d165eeaa5a25\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-92cecb20-ff65-4be7-8de8-d165eeaa5a25')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-92cecb20-ff65-4be7-8de8-d165eeaa5a25 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# See top 10 records of count_df data\n",
        "count_df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "yyoHc_cnX19J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73a40250-1f69-4df7-e038-3ac3a6c7a58b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.transpose of                                          user_id             song_id\n",
              "count                                    2000000             2000000\n",
              "unique                                     76353               10000\n",
              "top     6d625c6557df84b60d90426c0116138b617b9449  SOFRQTD12A81C233C0\n",
              "freq                                         711                8277>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# See the info of the count_df data\n",
        "count_df.describe(include='object').transpose"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# See the info of the count_df data\n",
        "count_df.describe(exclude='object').transpose"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BxiCdo1TjDT",
        "outputId": "6432800a-59bf-40e2-afd3-91fd823ee012"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.transpose of          play_count\n",
              "count  2.000000e+06\n",
              "mean   3.045485e+00\n",
              "std    6.579720e+00\n",
              "min    1.000000e+00\n",
              "25%    1.000000e+00\n",
              "50%    1.000000e+00\n",
              "75%    3.000000e+00\n",
              "max    2.213000e+03>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize= (7,1))\n",
        "sns.boxplot(x = count_df[\"play_count\"]\n",
        "            , color = 'grey').set_xlabel(\"play count distribution\")\n",
        "fig.tight_layout()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "A6UF_2dVbWNG",
        "outputId": "eea46b7c-f965-4cc0-a6a8-d6a2fb226d92"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 700x100 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Data Multivariate EDA"
      ],
      "metadata": {
        "id": "UJ__z0zqXSWq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "foRLtNXViYJl"
      },
      "outputs": [],
      "source": [
        "#### Pandas Report for detailed view original dataset\n",
        "# Use df_copy\n",
        "count_profile = ProfileReport(count_df\n",
        "                        , title=\"Count Info Report\"\n",
        "                         #, subtitle=\"Original Dataset\"\n",
        "                         )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "lLrX8glxijFw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "afd7649e65f64c2dbcafdc8ec5bfeaaa",
            "feae9b4ef96e443cb168441155363e79",
            "43937867ade64762b429e685acb56cca",
            "c1f0742677a2454286bbde4f5880a18e",
            "5a67f0ba31b0452d91133ed5a775dcdf",
            "7f192e7b7cc94ca49f094b91b3d5211d",
            "6eb69ece776540ec9d11ca44c4d6e777",
            "077aeb90900e4ee79c799eab7574e866",
            "79807958c0a141538a293559b8655d2b",
            "4ea583c5fdb147c9bde0b01e8038c97b",
            "7a3f4c5907f94663be2afaeaf1c8aeeb"
          ]
        },
        "outputId": "b8569081-727f-4667-a251-e5b627022e9a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "afd7649e65f64c2dbcafdc8ec5bfeaaa"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#count_profile.to_notebook_iframe()\n",
        "count_profile.to_file(\"count_ds_report_001.html\")       # for download"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Observations:**\n",
        "\n",
        "*   song_id can be used as key for merging (10000 unique - top song SOFRQTD12A81C233C0 with 8277 x)\n",
        "*   user_id can be used as key for merging (76353 unique - top user ends with b9449 with 711 x)\n",
        "*   S1 can be used for popularity based recommendation\n",
        "\n"
      ],
      "metadata": {
        "id": "Hxfnq2UwSYew"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kkP8NuHWGBP"
      },
      "source": [
        "#### S2) **Song dataset**\n",
        "Dataset defined by 1000000 x 5 variables. Includes the song information (song_title, song_release, song_artist, song_year) along with song_id which can be used for merging as as a reference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "W3rguzkMe6U_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0962059f-9056-474f-a36f-30bcfeb13ce9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000000, 5) \n",
            "               song_id              title                release  \\\n",
            "0  SOQMMHC12AB0180CB8       Silent Night  Monster Ballads X-Mas   \n",
            "1  SOVFVAK12A8C1350D9        Tanssi vaan            Karkuteillä   \n",
            "2  SOGTUKN12AB017F4F1  No One Could Ever                 Butter   \n",
            "\n",
            "        artist_name  year  \n",
            "0  Faster Pussy cat  2003  \n",
            "1  Karkkiautomaatti  1995  \n",
            "2    Hudson Mohawke  2006  \n"
          ]
        }
      ],
      "source": [
        "print(song_df.shape, \"\\n\", song_df.head(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "YD5QlVr7eU4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eff9943b-9ce6-47c9-efda-65e02443a05c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(999980, 5) \n",
            "\n",
            "                    song_id            song_title             song_release  \\\n",
            "154532  SOYAMSA12A6D4F4A8C                 Train    Words Came Back To Me   \n",
            "608458  SOQFGGR12AB018A930            A un Amigo             Las Clasicas   \n",
            "309864  SOWAACA12AB01823AD  Shouldn't I Love Him  Stay Out Of The Kitchen   \n",
            "\n",
            "           song_artist  song_year  \n",
            "154532  Sonya Kitchell       2006  \n",
            "608458     Los Dandy's          0  \n",
            "309864      Mable John          0  \n"
          ]
        }
      ],
      "source": [
        "temp = song_df\n",
        "\n",
        "temp = temp.dropna(axis=0)                            # drop na's\n",
        "#temp = temp.drop_duplicates()                        # drop duplicate rows  | To do after merge\n",
        "#temp = temp[temp['year'] != 0]                       # dropping all year info  == 0 | To do after merge\n",
        "\n",
        "temp.columns = ['song_id','song_title', 'song_release', 'song_artist', 'song_year'] # Adding column names\n",
        "\n",
        "print(temp.shape, \"\\n\\n\", temp.sample(3))\n",
        "#song_df = temp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# See the info of the count_df data\n",
        "song_df.describe(include='object').transpose"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Cu0zP1ST0Al",
        "outputId": "f6953060-3d38-4f14-df58-d2c4ad33b5bf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.transpose of                    song_id   title        release      artist_name\n",
              "count              1000000  999985         999995          1000000\n",
              "unique              999056  702428         149288            72665\n",
              "top     SOUYQYY12AF72A000F   Intro  Greatest Hits  Michael Jackson\n",
              "freq                     3    1510           2014              194>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# See the info of the count_df data\n",
        "song_df.describe(exclude='object').transpose"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xE7jlAEzT4gO",
        "outputId": "df2e2531-51e8-4716-8120-59106da1a866"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.transpose of                  year\n",
              "count  1000000.000000\n",
              "mean      1030.325652\n",
              "std        998.745002\n",
              "min          0.000000\n",
              "25%          0.000000\n",
              "50%       1969.000000\n",
              "75%       2002.000000\n",
              "max       2011.000000>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### Pandas Report for detailed view original dataset\n",
        "# Use df_copy\n",
        "song_profile = ProfileReport(song_df\n",
        "                             , title=\"Song Info Report\"\n",
        "                             #, subtitle=\"Original Dataset\"\n",
        "                             )"
      ],
      "metadata": {
        "id": "AuEEMsqCaEcl"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "song_profile.to_notebook_iframe()\n",
        "#song_profile.to_file(\"song_ds_report_001.html\")       # for download"
      ],
      "metadata": {
        "id": "49D71PVSaDlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Year-wise analysis\n",
        "\n",
        "# year based songs listened\n",
        "\n",
        "# year based Song that has been played most\n",
        "\n",
        "# Max number of songs played in a year\n",
        "\n",
        "# Other univariate and bivariate analysis"
      ],
      "metadata": {
        "id": "77nt3rIaWsKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "\n",
        "*   song_id: 999056 unique and top 1 x 3\n",
        "*   title: 702428 unique and top 1 = 'Intro'  (most Albums include an Intro 'song')\n",
        "*   release: 149288 unique and top 1 = 'Greatest Hits'\n",
        "*   artist_name: 72665 and top 1 = 'Michael Jackson'\n",
        "\n"
      ],
      "metadata": {
        "id": "0Lx2ahxpSOl4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luKdq6FDcR2u"
      },
      "source": [
        "#### Using the Spotify Web API for data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "cDTu6teL4Wzw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "5b778d4a-9b38-4486-df8b-cb01b7f07d65"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'SOVFVAK12A8C1350D9'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "temp['song_id'][1]        # example of song_id (to be used for spotipy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp['song_title'][1]        # example of song_id (to be used for spotipy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "pScpYejzRstS",
        "outputId": "931b094c-1dc0-4c38-f9f5-1b3831b1c0a1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tanssi vaan'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIe0x2CUfHF3"
      },
      "source": [
        "[Spotify Web Developer instructions](https://developer.spotify.com/documentation/web-api/concepts/spotify-uris-ids)\n",
        "\n",
        "[Spotify Web API instructions](https://developer.spotify.com/documentation/web-api/reference/get-an-artist)\n",
        "\n",
        "[Using Spotify Web App](https://garrecht-metzger.medium.com/getting-started-with-the-spotify-api-using-spotipy-bfb2340293c9)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSdsdGffcW1s"
      },
      "outputs": [],
      "source": [
        "# Replace 'YOUR_CLIENT_ID', 'YOUR_CLIENT_SECRET', and 'YOUR_REDIRECT_URI' with your actual credentials\n",
        "client_id = '930c85172af549c7bed7661f025edf11'\n",
        "client_secret = 'b33c88126c014981b3fc1d7c426d3a1c'\n",
        "redirect_uri = 'http://localhost:8888/callback'\n",
        "\n",
        "# Set up Spotify API credentials\n",
        "sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(client_id=client_id, client_secret=client_secret))\n",
        "\n",
        "# Example: Augmenting a dataset using song IDs\n",
        "song_ids = temp['song_id']                   #--> Spotify IDs seem not to be valid\n",
        "\n",
        "# Initialize a list to store augmented data\n",
        "augmented_data = []\n",
        "\n",
        "# Retrieve information for each song ID\n",
        "for song_id in song_ids:\n",
        "    try:\n",
        "        track_info = sp.track(song_id)\n",
        "        artist_info = sp.artist(track_info['artists'][0]['id'])\n",
        "\n",
        "        # Extract relevant information\n",
        "        track_name = track_info['name']\n",
        "        artist_name = artist_info['name']\n",
        "        release_date = track_info['album']['release_date']\n",
        "        popularity = track_info['popularity']\n",
        "        artist_genres = artist_info['genres']\n",
        "\n",
        "        # Add the augmented data to the list\n",
        "        augmented_data.append({\n",
        "            'song_id': song_id,\n",
        "            'track_name': track_name,\n",
        "            'artist_name': artist_name,\n",
        "            'release_date': release_date,\n",
        "            'popularity': popularity,\n",
        "            'genres': artist_genres\n",
        "        })\n",
        "    #except SpotifyException as e:\n",
        "        #print(f\"Error for song ID {song_id}: {e}\")\n",
        "\n",
        "# Convert the augmented data to a DataFrame\n",
        "augmented_df = pd.DataFrame(augmented_data)\n",
        "\n",
        "# Display the augmented DataFrame\n",
        "print(\"Augmented DataFrame:\")\n",
        "print(augmented_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQirn6HyiDog"
      },
      "source": [
        "Spotify IDs seem not to be valid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImDX2AW5cQSA"
      },
      "source": [
        "##### Text normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9yT4ZnsbUgF"
      },
      "outputs": [],
      "source": [
        "## Normalize Text variables\n",
        "\n",
        "import re\n",
        "# from nltk.corpus import stopwords\n",
        "# from nltk.stem import PorterStemmer\n",
        "\n",
        "# Function to perform text normalization\n",
        "def normalize_text(text):\n",
        "\n",
        "    text = text.lower()                                                           # Convert to lowercase\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)                                           # Remove punctuation\n",
        "    # stop_words = set(stopwords.words('english'))                                # Remove stop words (using NLTK library)\n",
        "    # text = ' '.join([word for word in text.split() if word not in stop_words])\n",
        "    # stemmer = PorterStemmer()                                                   # Stemming (using Porter Stemmer from NLTK)\n",
        "    # text = ' '.join([stemmer.stem(word) for word in text.split()])\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYDFT6W8cHfp"
      },
      "outputs": [],
      "source": [
        "# Apply the normalization function to the 'TextColumn'\n",
        "temp['song_title'] = temp['song_title'].apply(normalize_text)\n",
        "temp['song_release'] = temp['song_release'].apply(normalize_text)\n",
        "temp['song_artist'] = temp['song_artist'].apply(normalize_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8Up6R2PcTNL"
      },
      "outputs": [],
      "source": [
        "song_df = temp\n",
        "#temp = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKe4sAjslYsv"
      },
      "source": [
        "##### Pandas Report Songs Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45TkETYZcdtM"
      },
      "outputs": [],
      "source": [
        "#### Pandas Report original dataset\n",
        "# Use df_copy\n",
        "#profile_song = ProfileReport(song_df\n",
        "#                        , title=\"Song Info Report\"\n",
        "#                        #, subtitle=\"Original Dataset\"\n",
        "#                        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZ4VddZIclwo"
      },
      "outputs": [],
      "source": [
        "#profile_song.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ze2TlWxpYadn"
      },
      "source": [
        "#### **Final Observations and Insights:**\n",
        "\n",
        "*   Song data:\n",
        "    *  data structure: Prunned data frame has 5 variables (4 cat and 1 num) x 999980 observations. All other observations (20) were dropped as they had na's.\n",
        "    *  There are 505 rows (0.1%)  that are duplicated that will  be dropped\n",
        "    *  48.4% of year var has values = 0 values. The ranges of year goes from 1922 - 2011 --> FIXED\n",
        "\n",
        "\n",
        "*   Count data:\n",
        "    *  Dataset has no missing data or dupliate rows\n",
        "    *  Mean value of song_count is 3.0454845 whit t=values ranging from 1 - 2000\n",
        "    *  56.9% of songs are played 1 x. Clear presence of outliers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgj_xswhlgn3"
      },
      "source": [
        "#### Create subset for rapid testing (0.1%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svIrmZExaQ2h"
      },
      "outputs": [],
      "source": [
        "# Create sample subsets to go through project quickly\n",
        "\n",
        "# count_df = count_df .sample(frac=0.01, random_state=42)\n",
        "# song_df = song_df.sample(frac=0.01, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj5MdhYhWXJ2"
      },
      "source": [
        "### **Final Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTeurvID2T9U"
      },
      "outputs": [],
      "source": [
        "# Left merge the count_df and song_df data on \"song_id\". Drop duplicates from song_df data simultaneously\n",
        "## Name the obtained dataframe as \"df\"\n",
        "\n",
        "temp = pd.merge( count_df # 2000000\n",
        "                , song_df # 515132 (after cleaning)\n",
        "                , on='song_id'\n",
        "                , how='inner'       # when performing a left join NA\"s are created\n",
        "                )\n",
        "\n",
        "# df= temp.drop_duplicates(subset='song_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_nQYEAVa-Pd"
      },
      "outputs": [],
      "source": [
        "temp.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UX5Psoe4bDVs"
      },
      "outputs": [],
      "source": [
        "temp.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9CRBAW3lnwj"
      },
      "outputs": [],
      "source": [
        "temp = temp.drop_duplicates()                        # drop duplicate rows  | To do after merge\n",
        "temp = temp[temp['song_year'] != 0]                 # dropping all year info  == 0 | To do after merge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o98r3rTgnEbc"
      },
      "outputs": [],
      "source": [
        "df_final = temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBFb8ttVlxf1"
      },
      "outputs": [],
      "source": [
        "df_final.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWeY9ZT43XFX"
      },
      "source": [
        "**Think About It:** As the user_id and song_id are encrypted. Can they be encoded to numeric features?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zt3bMBhmm5zD"
      },
      "source": [
        "## Dataset prunning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxeoOVxh2T9U"
      },
      "outputs": [],
      "source": [
        "# Apply label encoding for \"user_id\" and \"song_id\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Q9EFYwj35Ju"
      },
      "source": [
        "**Think About It:** As the data also contains users who have listened to very few songs and vice versa, is it required to filter the data so that it contains users who have listened to a good count of songs and vice versa?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcY5LKAQvk9J"
      },
      "source": [
        "A dataset of size 2000000 rows x 7 columns can be quite large and may require a lot of computing resources to process. This can lead to long processing times and can make it difficult to train and evaluate your model efficiently.\n",
        "In order to address this issue, it may be necessary to trim down your dataset to a more manageable size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWsVTmP-m0A2"
      },
      "outputs": [],
      "source": [
        "print(df_final.info())\n",
        "print(\"\\n\")\n",
        "# check play_count\n",
        "print(df_final.describe(exclude='object').transpose())\n",
        "# deal with year = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFtvyAhjn90y"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize= (7,1))\n",
        "sns.boxplot(x = df_final[\"play_count\"]\n",
        "            , color = 'grey').set_xlabel(\"play_count distribution\")\n",
        "fig.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKElzYqwoYxO"
      },
      "outputs": [],
      "source": [
        "# Prunning outliers by Calculating the IQR (Interquartile Range)\n",
        "temp = df_final\n",
        "f1p = temp['play_count'].quantile(0.01)\n",
        "l1p = temp['play_count'].quantile(0.99)\n",
        "IQR = l1p - f1p\n",
        "\n",
        "# Define a threshold for identifying outliers\n",
        "outlier_threshold = 1.5\n",
        "\n",
        "# Remove outliers\n",
        "df_no_outliers = temp[(temp['play_count'] >= f1p - outlier_threshold * IQR) & (temp['play_count'] <= l1p + outlier_threshold * IQR)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlArbhVJpGax"
      },
      "outputs": [],
      "source": [
        "print(df_no_outliers.describe(exclude='object').transpose())   # any songs with more than 63% plays should be dropped"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e5arPYNmWh9"
      },
      "source": [
        "Todo: Should Outliers be also taken into consideration for selection criteria"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOazNfcSmcru"
      },
      "source": [
        "##### Dataset Pruning by Selection Criteria: Ratings CUTOFF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GGH9TW0_9uX"
      },
      "outputs": [],
      "source": [
        "# Get the column containing the users\n",
        "users = df_final.user_id\n",
        "# Create a dictionary from users to their number of songs\n",
        "ratings_count = dict()\n",
        "for user in users:\n",
        "    # If we already have the user, just add 1 to their rating count\n",
        "    if user in ratings_count:\n",
        "        ratings_count[user] += 1\n",
        "    # Otherwise, set their rating count to 1\n",
        "    else:\n",
        "        ratings_count[user] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cc6mOK7_9uX"
      },
      "outputs": [],
      "source": [
        "RATINGS_CUTOFF = 90\n",
        "remove_users = []\n",
        "for user, num_ratings in ratings_count.items():\n",
        "    if num_ratings < RATINGS_CUTOFF:\n",
        "        remove_users.append(user)\n",
        "df = df_final.loc[~df_final.user_id.isin(remove_users)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lxRzeMfpznC"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEDCSztqmnqW"
      },
      "source": [
        "##### Dataset Pruning by Selection Criteria: User CUTOFF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5BS-Wk5_9uY"
      },
      "outputs": [],
      "source": [
        "# Get the column containing the songs\n",
        "songs = df.song_id\n",
        "# Create a dictionary from songs to their number of users\n",
        "ratings_count = dict()\n",
        "for song in songs:\n",
        "    # If we already have the song, just add 1 to their rating count\n",
        "    if song in ratings_count:\n",
        "        ratings_count[song] += 1\n",
        "    # Otherwise, set their rating count to 1\n",
        "    else:\n",
        "        ratings_count[song] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nCtGwGO_9uY"
      },
      "outputs": [],
      "source": [
        "# We want our song to be listened by at least 120 users to be considered (why?)\n",
        "RATINGS_CUTOFF = 120\n",
        "remove_songs = []\n",
        "for song, num_ratings in ratings_count.items():\n",
        "    if num_ratings < RATINGS_CUTOFF:\n",
        "        remove_songs.append(song)\n",
        "df_final= df.loc[~df.song_id.isin(remove_songs)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJqEn0kgp-qP"
      },
      "outputs": [],
      "source": [
        "df_final.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIQdyIvso6KN"
      },
      "source": [
        "##### Dataset Pruning by Selection Criteria: Play_Count CUTOFF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qaKeoMcGpad"
      },
      "outputs": [],
      "source": [
        "# Drop records with play_count more than(>) 5\n",
        "df_final=df_final[df_final.play_count<=5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aL1JZ00o5JtQ"
      },
      "outputs": [],
      "source": [
        "# Check the shape of the data\n",
        "df_final.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9Iovuh_qLgY"
      },
      "source": [
        "A total of 138285 x 7 remains after applying pruning selection criteria."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aCP3jwyQqdgr"
      },
      "outputs": [],
      "source": [
        "#### Pandas Report original dataset\n",
        "# Use df_copy\n",
        "profile_final = ProfileReport(df_final\n",
        "                        , title=\"Final dataset Report\"\n",
        "                        #, subtitle=\"Original Dataset\"\n",
        "                        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzU8gkzgqhOz"
      },
      "outputs": [],
      "source": [
        "profile_final.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wm-vfhzSWQm7"
      },
      "source": [
        "Final Dataset (df_final)\n",
        "\n",
        "| Dataset statistics            |         |\n",
        "| ----------------------------- | ------- |\n",
        "| Number of variables           | 7       |\n",
        "| Number of observations        | 70379   |\n",
        "| Missing cells                 | 0       |\n",
        "| Missing cells (%)             | 0.00%   |\n",
        "| Duplicate rows                | 0       |\n",
        "| Duplicate rows (%)            | 0.00%   |\n",
        "| Total size in memory          | 4.3 MiB |\n",
        "| Average record size in memory | 64.0 B  |\n",
        "\n",
        "Alerts:\n",
        "\n",
        "      *  song_year has 23399 (16.9%) zeros ---> FIXED\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZcr1Eke2T9W"
      },
      "source": [
        "## **Exploratory Data Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQ5I4hJoZE4R"
      },
      "source": [
        "### **Numerical Variables EDA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDWmXxrZqyjs"
      },
      "outputs": [],
      "source": [
        "# numerical variables\n",
        "print(df_final.describe(exclude='object').transpose())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_xCNlxyZfdP"
      },
      "outputs": [],
      "source": [
        "# Create a figure with two subplots\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(7, 2))\n",
        "# p1: top users by ratings\n",
        "#sns.barplot(x='song_id', y='play_count', data=df_final, color='black', ax=axes[0])\n",
        "sns.boxplot(x = df_final[\"play_count\"], color = 'grey', ax=axes[0])\n",
        "# p2: ratings distribution (min = 5 given selection criteria)\n",
        "sns.histplot(df_final['play_count'], bins=3, kde=True, color='black', ax=axes[1])\n",
        "fig.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByuHmvWDeBJI"
      },
      "source": [
        "### **Categorical Variables EDA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnniZnwTTava"
      },
      "outputs": [],
      "source": [
        "# categorical variables\n",
        "print(df_final.describe(include='object').transpose())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jF6Hok3_ZQvM"
      },
      "outputs": [],
      "source": [
        "# Multivariate categorical analysis\n",
        "df_final.groupby(['song_id','song_title','song_year'])['play_count'].agg(['mean', 'count']).sort_values(by='count', ascending=False).reset_index().head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joFF5zndX1Dk"
      },
      "source": [
        "Songs played in a year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQp2iVMC2T9Y"
      },
      "outputs": [],
      "source": [
        "# Find out the number of songs played in a year\n",
        "  # Hint: Use groupby function on the 'year' column\n",
        "top_songs_year = df_final.groupby(['song_year'])['play_count'].agg(['mean', 'count']).sort_values(['song_year'],ascending=False).reset_index()\n",
        "round(top_songs_year).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZCkOiAB2T9Y"
      },
      "outputs": [],
      "source": [
        "# Create a barplot plot with y label as \"number of titles played\" and x -axis year\n",
        "\n",
        "# Set the figure size\n",
        "fig = plt.figure(figsize= (7,4))\n",
        "sns.barplot(x='song_year', y='count', data=top_songs_year, color='black')\n",
        "# Set the x label of the plot\n",
        "plt.xlabel(\"song_year\")\n",
        "# Set the y label of the plot\n",
        "plt.ylabel('number of titles played')\n",
        "# Show the plot\n",
        "fig.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvk-YAo-eGGW"
      },
      "source": [
        "#### **Observations and Insights:**\n",
        "\n",
        "Unique ocurrences:\n",
        "\n",
        "                  *   There are 2187 unique users\n",
        "                  *   There are 343 unique songs_ids\n",
        "                  *   There are 346 unique song_titles\n",
        "                  *   There are 275 unique song_releases\n",
        "                  *   There are 152 unique song_artists\n",
        "\n",
        "Top ocurrences:\n",
        "\n",
        "*    Top songs\n",
        "\n",
        "          *   Top songs_id is SOWCKVR12A8C142411 with 1538 freq\n",
        "          *   Top song_title is use somebody with 1538 - most probably with SOWCKVR12A8C142411 song_id\n",
        "\n",
        "| rank | song_title          | freq | freq_% |\n",
        "| ---- | ------------------- | ---- | ------ |\n",
        "| 1    | use somebody        | 1602 | 1.20%  |\n",
        "| 2    | yellow              | 1264 | 0.90%  |\n",
        "| 3    | dont stop the music | 960  | 0.70%  |\n",
        "| 4    | somebody to love    | 920  | 0.70%  |\n",
        "| 5    | love story          | 910  | 0.70%  |\n",
        "\n",
        "*    Top releases\n",
        "\n",
        "          *   Top song_release is my worlds with 1913 freq\n",
        "\n",
        "| rank | song_release                     | freq | freq_% |\n",
        "| ---- | -------------------------------- | ---- | ------ |\n",
        "| 1    | my worlds                        | 1967 | 1.40%  |\n",
        "| 2    | ray guns are not just the future | 1855 | 1.30%  |\n",
        "| 3    | vampire weekend                  | 1754 | 1.30%  |\n",
        "| 4    | hell train                       | 1708 | 1.20%  |\n",
        "| 5    | give up                          | 1632 | 1.20%  |\n",
        "\n",
        "*    Top song_artists\n",
        "          *   Top song_artists is coldplay with 6313 freq\n",
        "\n",
        "| rank | song_artist          | freq | freq_% |\n",
        "| ---- | -------------------- | ---- | ------ |\n",
        "| 1    | coldplay             | 6527 | 4.70%  |\n",
        "| 2    | kings of leon        | 4441 | 3.20%  |\n",
        "| 3    | the killers          | 4254 | 3.10%  |\n",
        "| 4    | florence the machine | 3046 | 2.20%  |\n",
        "| 5    | justin bieber        | 2858 | 2.10%  |\n",
        "\n",
        "*   Top users\n",
        "\n",
        "        *   Top user is ce5c912bb8044f23fc0fc31bd986b8d0a7303db5 with 278 freq\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWO4C8KsK_5e"
      },
      "source": [
        "Now that we have explored the data, let's apply different algorithms to build recommendation systems.\n",
        "\n",
        "**Note:** Use the shorter version of the data, i.e., the data after the cutoffs as used in Milestone 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VThYg7voGIz"
      },
      "source": [
        "## Building various models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ituk9wA4Idib"
      },
      "source": [
        "### **Popularity-Based Recommendation Systems**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "462hsbxaI1ED"
      },
      "source": [
        "Let's take the count and sum of play counts of the songs and build the popularity recommendation systems based on the sum of play counts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXhBZlDE-jEu"
      },
      "outputs": [],
      "source": [
        "# Calculating average play_count\n",
        "       # Hint: Use groupby function on the song_id column\n",
        "\n",
        "avg_counts= df_final.groupby('song_id')['play_count'].mean().reset_index()\n",
        "\n",
        "# Calculating the frequency a song is played\n",
        "      # Hint: Use groupby function on the song_id column\n",
        "count_counts = df_final.groupby('song_id')['play_count'].count().reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2XYdXvWdyys"
      },
      "outputs": [],
      "source": [
        "# Making a dataframe with the average_count and play_freq\n",
        "avg_play_counts = df_final.groupby(['song_id','song_title'])['play_count'].agg(['mean', 'count']).sort_values(by='count', ascending=False).reset_index()\n",
        "\n",
        "# Let us see the first five records of the final_play dataset\n",
        "avg_play_counts.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnCT-A7RK_5g"
      },
      "source": [
        "Now, let's create a function to find the top n songs for a recommendation based on the average play count of song. We can also add a threshold for a minimum number of playcounts for a song to be considered for recommendation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QiT9FV3GNCrb"
      },
      "outputs": [],
      "source": [
        "# Build the function to find top n songs\n",
        "\n",
        "# p1: avg_play_counts: dataframe to sort\n",
        "# p2: n: n products\n",
        "# p3: min_playcounts: def what a min interaction is (min())\n",
        "\n",
        "def top_n_songs(df, n, min_playcount_def):\n",
        "\n",
        "    # Finding songs with minimum number of playcounts\n",
        "    #min_playcount_def = df['count'].min()                                     # def a min playcount\n",
        "    min_recommendations = df[df['count'] >=  min_playcount_def]      # recommendations that comprise def of min playcounts had to be fixed to be >= as they are min requirements\n",
        "\n",
        "    # Sorting values with respect to average rating\n",
        "    sorted_recommendations = min_recommendations.sort_values(['count'], ascending = False)#.reset_index()\n",
        "\n",
        "    return sorted_recommendations[:n]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyXPU4KOyDZC"
      },
      "outputs": [],
      "source": [
        "# Testing function\n",
        "\n",
        "result = top_n_songs(avg_play_counts, 3, 5)\n",
        "\n",
        "test = avg_play_counts[avg_play_counts['count'] >=  5].sort_values(['count'], ascending = False)\n",
        "\n",
        "print(\n",
        "      avg_play_counts.head(3)\n",
        "      , \"\\n\\n\"\n",
        "      , result # getting the index\n",
        "      , \"\\n\\n\"\n",
        "      , test[:3]\n",
        "      )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpZt_BeXgz4F"
      },
      "outputs": [],
      "source": [
        "# Recommend top 10 songs using the function defined above\n",
        "top_n_songs(avg_play_counts, 10, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gf13HrPPJeWT"
      },
      "source": [
        "### **User User Similarity-Based Collaborative Filtering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROcEpduohdua"
      },
      "source": [
        "In this type of recommendation system, we do not need any information about the users or items. We only need user item interaction data to build a collaborative recommendation system. For example playcounts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBW4BUhWTsnm"
      },
      "source": [
        "### Some useful functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhFa_4aHHchr"
      },
      "source": [
        "Below is the function to calculate precision@k and recall@k, RMSE, and F1_Score@k to evaluate the model performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOvOgjGWrMVV"
      },
      "source": [
        "**Think About It:** Which metric should be used for this problem to compare different models?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rxn-GahOTsnm"
      },
      "outputs": [],
      "source": [
        "# The function to calulate the RMSE, precision@k, recall@k, and F_1 score\n",
        "def precision_recall_at_k(model, k = 30, threshold = 1.5):\n",
        "    \"\"\"Return precision and recall at k metrics for each user\"\"\"\n",
        "\n",
        "    # First map the predictions to each user.\n",
        "    user_est_true = defaultdict(list)\n",
        "\n",
        "    # Making predictions on the test data\n",
        "    predictions=model.test(testset)\n",
        "\n",
        "    for uid, _, true_r, est, _ in predictions:\n",
        "        user_est_true[uid].append((est, true_r))\n",
        "\n",
        "    precisions = dict()\n",
        "    recalls = dict()\n",
        "    for uid, user_ratings in user_est_true.items():\n",
        "\n",
        "        # Sort user ratings by estimated value\n",
        "        user_ratings.sort(key = lambda x : x[0], reverse = True)\n",
        "\n",
        "        # Number of relevant items\n",
        "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
        "\n",
        "        # Number of recommended items in top k\n",
        "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[ : k])\n",
        "\n",
        "        # Number of relevant and recommended items in top k\n",
        "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
        "                              for (est, true_r) in user_ratings[ : k])\n",
        "\n",
        "        # Precision@K: Proportion of recommended items that are relevant\n",
        "        # When n_rec_k is 0, Precision is undefined. We here set Precision to 0 when n_rec_k is 0\n",
        "\n",
        "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
        "\n",
        "        # Recall@K: Proportion of relevant items that are recommended\n",
        "        # When n_rel is 0, Recall is undefined. We here set Recall to 0 when n_rel is 0\n",
        "\n",
        "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
        "\n",
        "    # Mean of all the predicted precisions are calculated\n",
        "    precision = round((sum(prec for prec in precisions.values()) / len(precisions)), 3)\n",
        "\n",
        "    # Mean of all the predicted recalls are calculated\n",
        "    recall = round((sum(rec for rec in recalls.values()) / len(recalls)), 3)\n",
        "\n",
        "    accuracy.rmse(predictions)\n",
        "\n",
        "    # Command to print the overall precision\n",
        "    print('Precision: ', precision)\n",
        "\n",
        "    # Command to print the overall recall\n",
        "    print('Recall: ', recall)\n",
        "\n",
        "    # Formula to compute the F-1 score\n",
        "    print('F_1 score: ', round((2 * precision * recall) / (precision + recall), 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcmLRxH4IjfG"
      },
      "source": [
        "**Think About It:** In the function precision_recall_at_k above the threshold value used is 1.5. How precision and recall are affected by changing the threshold? What is the intuition behind using the threshold value of 1.5?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGfYDiOCpe4X"
      },
      "outputs": [],
      "source": [
        "# Instantiating Reader scale with expected rating scale\n",
        " #use rating scale (0, 5)\n",
        "reader = Reader(rating_scale = (0, 5)) # min = 0 and max = 5 x played by user\n",
        "\n",
        "# Loading the dataset\n",
        " # Take only \"user_id\",\"song_id\", and \"play_count\"\n",
        "data = Dataset.load_from_df(df_final[['user_id', 'song_id', 'play_count']], reader)      # can be solved with S1 count_df\n",
        "\n",
        "# Splitting the data into train and test dataset\n",
        " # Take test_size = 0.4, random_state = 42\n",
        "trainset, testset = train_test_split(data, test_size = 0.2, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKvaVlWqedd6"
      },
      "outputs": [],
      "source": [
        "# test splitting:\n",
        "print(reader, \"\\n\\n\"\n",
        "      , data, \"\\n\\n\"\n",
        "      , trainset, \"\\n\\n\"\n",
        "      , testset[:2]\n",
        "      )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuTmLjUP1aED"
      },
      "source": [
        "**Think About It:** How changing the test size would change the results and outputs?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8A71jB6Eel6w"
      },
      "source": [
        "### M1) Defining User - User Similarity Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vO3FL7iape8A",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Build the default user-user-similarity model\n",
        "# Declaring the similarity options\n",
        "sim_options = {'name': 'cosine',\n",
        "               'user_based': True}\n",
        "\n",
        "# KNN algorithm is used to find desired similar items\n",
        " # Use random_state = 1\n",
        "sim_user_user = KNNBasic(sim_options=sim_options\n",
        "                         , verbose=False\n",
        "                         , random_state=1)\n",
        "\n",
        "# Train the algorithm on the trainset, and predict play_count for the testset\n",
        "sim_user_user.fit(trainset)\n",
        "\n",
        "# Let us compute precision@k, recall@k, and f_1 score with k = 30\n",
        " # Use sim_user_user model\n",
        "precision_recall_at_k(sim_user_user)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzcdlWmer6GA"
      },
      "source": [
        "**Observations and Insights:**\n",
        "Baseline model is reasanoble but performance metrics can be improved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sxd23bZ9pe_x"
      },
      "outputs": [],
      "source": [
        "# Predicting play_count for a sample user with a listened song\n",
        "# Use any user id and song_id\n",
        "rand_index = np.random.randint(1, len(df_final))\n",
        "\n",
        "# Predicting rating for a sample user with an interacted product\n",
        "sim_user_user.predict(df_final['user_id'].iloc[rand_index]\n",
        "                      , df_final['song_id'].iloc[rand_index]\n",
        "                     # , r_ui = 5\n",
        "                      , verbose = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PbFcBj1PpfEV"
      },
      "outputs": [],
      "source": [
        "# Predicting play_count for a sample user with a song not-listened by the user\n",
        " #predict play_count for any sample user\n",
        "\n",
        "# using a function from the elective project:\n",
        "def n_users_not_interacted_with(n, data, song_id):\n",
        "    users_interacted_with_product = set(data[data['song_id'] == song_id]['user_id'])\n",
        "    all_users = set(data['user_id'])\n",
        "    return list(all_users.difference(users_interacted_with_product))[:n] # where n is the number of elements to get in the list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3qYMI4_iNzW"
      },
      "outputs": [],
      "source": [
        "n_users_not_interacted_with(5, df_final, 'SOMYXWV12A8C14232E')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BdvMaDDifek"
      },
      "outputs": [],
      "source": [
        "# Predicting play_count for a sample user with a song not-listened by the user\n",
        "sim_user_user.predict('ac89005519c8cfac509fabd82fdeb7add90dbc4f'\n",
        "                      , 'SOMYXWV12A8C14232E'\n",
        "                      #, r_ui =\n",
        "                      , verbose = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9EVM7DysC47"
      },
      "source": [
        "**Observations and Insights:**\n",
        "\n",
        "Legend:\n",
        "\n",
        "- uid: This stands for \"user id\" and represents the unique identifier of the user for whom the prediction was made. In this case, the user ID is '1ee591a388274035a4fd8a4ae40a9589d320bb9d'.\n",
        "\n",
        "- iid: This stands for \"item id\" and represents the unique identifier of the item (in this context, a song) for which the prediction was made. In this case, the item ID is 'SODACBL12A8C13C273'.\n",
        "\n",
        "- r_ui: This represents the \"real\" or actual rating given by the user for the item. In this case, the actual rating is 5.\n",
        "\n",
        "- est: This represents the estimated or predicted rating for the user-item pair. In this case, the predicted rating is approximately 1.66.\n",
        "\n",
        "- details: This is a dictionary containing additional details about the prediction. In this specific case, the details include the number of actual neighbors considered for the prediction (actual_k: 40) and whether the prediction was made without any issues (was_impossible: False).\n",
        "\n",
        "\n",
        "**Here's a summary of the prediction:**\n",
        "\n",
        "User '1ee591a388274035a4fd8a4ae40a9589d320bb9d' is predicted to give the song 'SODACBL12A8C13C273' a rating of approximately 1.66. The actual rating given by the user is 5. The prediction is based on collaborative filtering, and 40 nearest neighbors were considered in the process. No issues were encountered during the prediction process (was_impossible: False)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lt1QBiylsIOm"
      },
      "source": [
        "**Hyperparameter Tuning**\n",
        "\n",
        "Now, let's try to tune the model and see if we can improve the model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3diJPL7-tVw"
      },
      "outputs": [],
      "source": [
        "# Setting up parameter grid to tune the hyperparameters\n",
        "param_grid = {\n",
        "        'k':[40],                       # number of neighbors to consider (40 default also equal to the ones in round 1)\n",
        "        'min_k': [1],                   # minimum number of neighbors to take into account for aggregation\n",
        "        'sim_options': {\n",
        "        'name': ['cosine'\n",
        "                , 'pearson'\n",
        "                , 'msd']                # similarity metric (cosine or pearson). Consider all options\n",
        "}}\n",
        "\n",
        "# Performing 3-fold cross-validation to tune the hyperparameters\n",
        "gs = GridSearchCV(  KNNBasic\n",
        "                  , param_grid\n",
        "                  , measures = ['rmse']\n",
        "                  , cv = 3\n",
        "                  , n_jobs = -1)\n",
        "\n",
        "# Fitting the data\n",
        "# Use entire data for GridSearch\n",
        "gs.fit(data)\n",
        "\n",
        "# Best RMSE score\n",
        "print(\" Best RMSE score\", gs.best_score['rmse'], \"\\n\\n\")\n",
        "\n",
        "# Combination of parameters that gave the best RMSE score\n",
        "print(\"Combination of parameters for best RMSE score\", gs.best_params['rmse'], \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PujRJA8X_JEJ"
      },
      "outputs": [],
      "source": [
        "# Train the best model found in above gridsearch\n",
        "sim_options = {'name': 'msd'\n",
        "              , 'user_based': True}\n",
        "\n",
        "# Creating an instance of KNNBasic with optimal hyperparameter values\n",
        "sim_user_user_optimized = KNNBasic(sim_options=sim_options\n",
        "                                   , k = gs.best_params['rmse']['k']\n",
        "                                   , min_k=1\n",
        "                                   , random_state=1\n",
        "                                   , verbose=False)\n",
        "\n",
        "# Training the algorithm on the train set\n",
        "sim_user_user_optimized.fit(trainset)\n",
        "precision_recall_at_k(sim_user_user_optimized)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MH5OBZ7Nse6m"
      },
      "source": [
        "**Observations and Insights:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgV63lHiq1TV"
      },
      "outputs": [],
      "source": [
        "# Predict the play count for a user who has listened to the song. Take user_id 6958, song_id 1671 and r_ui = 2\n",
        "# REVIEW (!!)\n",
        "rand_index = np.random.randint(1, len(df_final))\n",
        "\n",
        "# Predicting rating for a sample user with an interacted product\n",
        "sim_user_user_optimized.predict(df_final['user_id'].iloc[rand_index]\n",
        "                      , df_final['song_id'].iloc[rand_index]\n",
        "                      , r_ui = 2\n",
        "                      , verbose = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXO2Ztjhq1bN"
      },
      "outputs": [],
      "source": [
        "# Predict the play count for a song that is not listened to by the user (with user_id 6958)\n",
        "sim_user_user.predict('ac89005519c8cfac509fabd82fdeb7add90dbc4f'\n",
        "                      , 'SOMYXWV12A8C14232E'\n",
        "                      #, r_ui =\n",
        "                      , verbose = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdpJ--8QWuzz"
      },
      "source": [
        "**Observations and Insights:______________**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQ9M4pplNbWS"
      },
      "source": [
        "**Think About It:** Along with making predictions on listened and unknown songs can we get 5 nearest neighbors (most similar) to a certain song?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbFle7cKmBJG"
      },
      "outputs": [],
      "source": [
        "# Use inner id 0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3ESobDynVNI"
      },
      "source": [
        "Below we will be implementing a function where the input parameters are:\n",
        "\n",
        "- data: A **song** dataset\n",
        "- user_id: A user-id **against which we want the recommendations**\n",
        "- top_n: The **number of songs we want to recommend**\n",
        "- algo: The algorithm we want to use **for predicting the play_count**\n",
        "- The output of the function is a **set of top_n items** recommended for the given user_id based on the given algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vW9V1Tk65HlY"
      },
      "outputs": [],
      "source": [
        "def get_recommendations(data, user_id, top_n, algo):\n",
        "\n",
        "    # Creating an empty list to store the recommended product ids\n",
        "    recommendations = []\n",
        "\n",
        "    # Creating an user item interactions matrix\n",
        "    user_song_interactions_matrix = data.pivot(index = 'user_id'\n",
        "                                              , columns = 'song_id'\n",
        "                                              , values = 'play_count')\n",
        "\n",
        "    # Extracting those business ids which the user_id has not visited yet\n",
        "    non_interacted_songs = user_song_interactions_matrix.loc[user_id][user_song_interactions_matrix.loc[user_id].isnull()].index.tolist()\n",
        "\n",
        "    # Looping through each of the business ids which user_id has not interacted yet\n",
        "    for song_id in non_interacted_songs:\n",
        "        # Predicting the ratings for those non visited restaurant ids by this user\n",
        "        est = algo.predict(user_id, song_id).est\n",
        "        # Appending the predicted ratings\n",
        "        recommendations.append((song_id, est))\n",
        "    # Sorting the predicted ratings in descending order\n",
        "    recommendations.sort(key = lambda x: x[1], reverse = True)\n",
        "    return recommendations[:top_n] # Returing top n highest predicted rating products for this user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWbR85mI5Hrk"
      },
      "outputs": [],
      "source": [
        "# Make top 5 recommendations for any user_id with a similarity-based recommendation engine\n",
        "rand_index = np.random.randint(1, len(df_final))\n",
        "\n",
        "recommendations = get_recommendations(df_final\n",
        "                                      , '57a9158b6b8306ae96682a63bc56c58391182dc8' #df_final['user_id'].iloc[rand_index]\n",
        "                                      , 5\n",
        "                                      , sim_user_user_optimized # adding the optimized model\n",
        "#                                     , sim_user_user     # adding the original model\n",
        "                                      )\n",
        "recommendations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5WfIX0Z6_q2"
      },
      "outputs": [],
      "source": [
        "# Building the dataframe for above recommendations with columns \"song_id\" and \"predicted_ratings\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyhThMOttWjj"
      },
      "source": [
        "**Observations and Insights:______________**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghwEJY2e7INB"
      },
      "source": [
        "### Correcting the play_counts and Ranking the above songs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39Hs7ZbO9v3O"
      },
      "outputs": [],
      "source": [
        "def ranking_songs(recommendations, final_rating):\n",
        "  # Sort the songs based on play counts\n",
        "\n",
        "  # Merge with the recommended songs to get predicted play_count\n",
        "\n",
        "  # Rank the songs based on corrected play_counts\n",
        "\n",
        "  # Sort the songs based on corrected play_counts\n",
        "\n",
        "  return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQvst41lOoMX"
      },
      "source": [
        "**Think About It:** In the above function to correct the predicted play_count a quantity 1/np.sqrt(n) is subtracted. What is the intuition behind it? Is it also possible to add this quantity instead of subtracting?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoiAL_vH8miC"
      },
      "outputs": [],
      "source": [
        "# Applying the ranking_songs function on the final_play data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOwwGsH8toLG"
      },
      "source": [
        "**Observations and Insights:______________**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgbzJKk7Tsnr"
      },
      "source": [
        "### Item Item Similarity-based collaborative filtering recommendation systems"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5RMcdzjTsns",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Apply the item-item similarity collaborative filtering model with random_state = 1 and evaluate the model performance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfdIJ6XWunx0"
      },
      "source": [
        "**Observations and Insights:______________**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5yILOxXRTsns"
      },
      "outputs": [],
      "source": [
        "# Predicting play count for a sample user_id 6958 and song (with song_id 1671) heard by the user\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSn8oK3JZsTc"
      },
      "outputs": [],
      "source": [
        "# Predict the play count for a user that has not listened to the song (with song_id 1671)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxE9fJ8Dupby"
      },
      "source": [
        "**Observations and Insights:______________**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5bcZ3HgTsnt"
      },
      "outputs": [],
      "source": [
        "# Apply grid search for enhancing model performance\n",
        "\n",
        "# Setting up parameter grid to tune the hyperparameters\n",
        "\n",
        "\n",
        "# Performing 3-fold cross-validation to tune the hyperparameters\n",
        "\n",
        "# Fitting the data\n",
        "\n",
        "\n",
        "# Find the best RMSE score\n",
        "\n",
        "# Extract the combination of parameters that gave the best RMSE score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXLxjLEQYvWk"
      },
      "source": [
        "**Think About It:** How do the parameters affect the performance of the model? Can we improve the performance of the model further? Check the list of hyperparameters [here](https://surprise.readthedocs.io/en/stable/knn_inspired.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSeiM1qeTsnt"
      },
      "outputs": [],
      "source": [
        "# Apply the best modle found in the grid search\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxXelRIluvfh"
      },
      "source": [
        "**Observations and Insights:______________**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gIBRRvdoTsnt"
      },
      "outputs": [],
      "source": [
        "# Predict the play_count by a user(user_id 6958) for the song (song_id 1671)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNEgcI9PTsnu"
      },
      "outputs": [],
      "source": [
        "# Predicting play count for a sample user_id 6958 with song_id 3232 which is not heard by the user\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yf3kDSepuwcw"
      },
      "source": [
        "**Observations and Insights:______________**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRJS4oDFTsnu"
      },
      "outputs": [],
      "source": [
        "# Find five most similar items to the item with inner id 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzoEbuZFTsnu"
      },
      "outputs": [],
      "source": [
        "# Making top 5 recommendations for any user_id  with item_item_similarity-based recommendation engine\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kXVTiysTsnv"
      },
      "outputs": [],
      "source": [
        "# Building the dataframe for above recommendations with columns \"song_id\" and \"predicted_play_count\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gewfmTATsnv"
      },
      "outputs": [],
      "source": [
        "# Applying the ranking_songs function\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ore9XTFgv5Np"
      },
      "source": [
        "**Observations and Insights:_________**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKgJpSA9vOOL"
      },
      "source": [
        "### Model Based Collaborative Filtering - Matrix Factorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJynidJCw-ti"
      },
      "source": [
        "Model-based Collaborative Filtering is a **personalized recommendation system**, the recommendations are based on the past behavior of the user and it is not dependent on any additional information. We use **latent features** to find recommendations for each user."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07-2PT5Ssjqm"
      },
      "outputs": [],
      "source": [
        "# Build baseline model using svd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWIhfdxXsjqm"
      },
      "outputs": [],
      "source": [
        "# Making prediction for user (with user_id 6958) to song (with song_id 1671), take r_ui = 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APm-uMSvcAMf"
      },
      "outputs": [],
      "source": [
        "# Making a prediction for the user who has not listened to the song (song_id 3232)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23tnRUJJxWTR"
      },
      "source": [
        "#### Improving matrix factorization based recommendation system by tuning its hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bM81V_hvtwv"
      },
      "outputs": [],
      "source": [
        "# Set the parameter space to tune\n",
        "\n",
        "\n",
        "# Performe 3-fold grid-search cross-validation\n",
        "\n",
        "\n",
        "# Fitting data\n",
        "\n",
        "# Best RMSE score\n",
        "\n",
        "# Combination of parameters that gave the best RMSE score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSgBRcL1xnVC"
      },
      "source": [
        "**Think About It**: How do the parameters affect the performance of the model? Can we improve the performance of the model further? Check the available hyperparameters [here](https://surprise.readthedocs.io/en/stable/matrix_factorization.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TA_7xe-nnhuu"
      },
      "outputs": [],
      "source": [
        "# Building the optimized SVD model using optimal hyperparameters\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3t5JdBmxz8l"
      },
      "source": [
        "**Observations and Insights:_________**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6C1PAfboM8_"
      },
      "outputs": [],
      "source": [
        "# Using svd_algo_optimized model to recommend for userId 6958 and song_id 1671\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1xjn3kOoQyg"
      },
      "outputs": [],
      "source": [
        "# Using svd_algo_optimized model to recommend for userId 6958 and song_id 3232 with unknown baseline rating\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qm732Wuvy76R"
      },
      "source": [
        "**Observations and Insights:_________**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LGeE2EB_n90"
      },
      "outputs": [],
      "source": [
        "# Getting top 5 recommendations for user_id 6958 using \"svd_optimized\" algorithm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ngiGSJU818M"
      },
      "outputs": [],
      "source": [
        "# Ranking songs based on above recommendations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SepUU1Efy_9Z"
      },
      "source": [
        "**Observations and Insights:_________**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57b31de5"
      },
      "source": [
        "### Cluster Based Recommendation System"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Xv2AZCszCdN"
      },
      "source": [
        "In **clustering-based recommendation systems**, we explore the **similarities and differences** in people's tastes in songs based on how they rate different songs. We cluster similar users together and recommend songs to a user based on play_counts from other users in the same cluster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0c4b20e4"
      },
      "outputs": [],
      "source": [
        "# Make baseline clustering model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11dbdc0f"
      },
      "outputs": [],
      "source": [
        "# Making prediction for user_id 6958 and song_id 1671\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dab1aaed"
      },
      "outputs": [],
      "source": [
        "# Making prediction for user (userid 6958) for a song(song_id 3232) not heard by the user\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2fd66f5"
      },
      "source": [
        "#### Improving clustering-based recommendation system by tuning its hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efe7d8e6"
      },
      "outputs": [],
      "source": [
        "# Set the parameter space to tune\n",
        "\n",
        "\n",
        "# Performing 3-fold grid search cross-validation\n",
        "\n",
        "# Fitting data\n",
        "\n",
        "# Best RMSE score\n",
        "\n",
        "# Combination of parameters that gave the best RMSE score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CS6aMVJLyj21"
      },
      "source": [
        "**Think About It**: How do the parameters affect the performance of the model? Can we improve the performance of the model further? Check the available hyperparameters [here](https://surprise.readthedocs.io/en/stable/co_clustering.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5a7a8a30"
      },
      "outputs": [],
      "source": [
        "# Train the tuned Coclustering algorithm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-Jvce1gznKa"
      },
      "source": [
        "**Observations and Insights:_________**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ba5b26b"
      },
      "outputs": [],
      "source": [
        "# Using co_clustering_optimized model to recommend for userId 6958 and song_id 1671\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ec582940"
      },
      "outputs": [],
      "source": [
        "# Use Co_clustering based optimized model to recommend for userId 6958 and song_id 3232 with unknown baseline rating\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjGUSMqrzoDH"
      },
      "source": [
        "**Observations and Insights:_________**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df9e28ba"
      },
      "source": [
        "#### Implementing the recommendation algorithm based on optimized CoClustering model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0f36e15"
      },
      "outputs": [],
      "source": [
        "# Getting top 5 recommendations for user_id 6958 using \"Co-clustering based optimized\" algorithm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1696941"
      },
      "source": [
        "### Correcting the play_count and Ranking the above songs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c186f13b",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Ranking songs based on the above recommendations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uJ_nZjBzvKH"
      },
      "source": [
        "**Observations and Insights:_________**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5U56oSNsR-F2"
      },
      "source": [
        "### Content Based Recommendation Systems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aTEqaOjhoEg"
      },
      "source": [
        "**Think About It:** So far we have only used the play_count of songs to find recommendations but we have other information/features on songs as well. Can we take those song features into account?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhUx2jgp4frC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UX826CsjR-F3"
      },
      "outputs": [],
      "source": [
        "# Concatenate the \"title\", \"release\", \"artist_name\" columns to create a different column named \"text\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdXw4U-wR-F4"
      },
      "outputs": [],
      "source": [
        "# Select the columns 'user_id', 'song_id', 'play_count', 'title', 'text' from df_small data\n",
        "\n",
        "# Drop the duplicates from the title column\n",
        "\n",
        "# Set the title column as the index\n",
        "\n",
        "# See the first 5 records of the df_small dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDcYHwZTR-F5"
      },
      "outputs": [],
      "source": [
        "# Create the series of indices from the data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UINF3Nwvwfr"
      },
      "outputs": [],
      "source": [
        "# Importing necessary packages to work with text data\n",
        "import nltk\n",
        "\n",
        "# Download punkt library\n",
        "\n",
        "\n",
        "# Download stopwords library\n",
        "\n",
        "\n",
        "# Download wordnet\n",
        "\n",
        "\n",
        "# Import regular expression\n",
        "\n",
        "\n",
        "# Import word_tokenizer\n",
        "\n",
        "\n",
        "# Import WordNetLemmatizer\n",
        "\n",
        "# Import stopwords\n",
        "\n",
        "\n",
        "# Import CountVectorizer and TfidfVectorizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt2vitlnhoEg"
      },
      "source": [
        "We will create a **function to pre-process the text data:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5QSSeUvR-F6"
      },
      "outputs": [],
      "source": [
        "# Create a function to tokenize the text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RI_onIGdR-F6"
      },
      "outputs": [],
      "source": [
        "# Create tfidf vectorizer\n",
        "\n",
        "# Fit_transfrom the above vectorizer on the text column and then convert the output into an array\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Beak6ODRR-F7"
      },
      "outputs": [],
      "source": [
        "# Compute the cosine similarity for the tfidf above output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Jjo3UHKhoEh"
      },
      "source": [
        " Finally, let's create a function to find most similar songs to recommend for a given song."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upANOISkR-F8"
      },
      "outputs": [],
      "source": [
        "# Function that takes in song title as input and returns the top 10 recommended songs\n",
        "def recommendations(title, similar_songs):\n",
        "\n",
        "\n",
        "\n",
        "    # Getting the index of the song that matches the title\n",
        "\n",
        "\n",
        "    # Creating a Series with the similarity scores in descending order\n",
        "\n",
        "\n",
        "    # Getting the indexes of the 10 most similar songs\n",
        "\n",
        "\n",
        "    # Populating the list with the titles of the best 10 matching songs\n",
        "\n",
        "\n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4EINBmkR-F8"
      },
      "source": [
        "Recommending 10 songs similar to Learn to Fly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohEK5dkVR-F8"
      },
      "outputs": [],
      "source": [
        "# Make the recommendation for the song with title 'Learn To Fly'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQ7iI5QJ0oem"
      },
      "source": [
        "**Observations and Insights:_________**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73367782"
      },
      "source": [
        "## **Conclusion and Recommendations**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5BT7Ocwqf5x"
      },
      "source": [
        "**1. Comparison of various techniques and their relative performance based on chosen Metric (Measure of success)**:\n",
        "- How do different techniques perform? Which one is performing relatively better? Is there scope to improve the performance further?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjc6vTcoqp6v"
      },
      "source": [
        "**2. Refined insights**:\n",
        "- What are the most meaningful insights from the data relevant to the problem?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hK6PMGUtoxVx"
      },
      "source": [
        "**3. Proposal for the final solution design:**\n",
        "- What model do you propose to be adopted? Why is this the best solution to adopt?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "luKdq6FDcR2u",
        "bvk-YAo-eGGW"
      ],
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "afd7649e65f64c2dbcafdc8ec5bfeaaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_feae9b4ef96e443cb168441155363e79",
              "IPY_MODEL_43937867ade64762b429e685acb56cca",
              "IPY_MODEL_c1f0742677a2454286bbde4f5880a18e"
            ],
            "layout": "IPY_MODEL_5a67f0ba31b0452d91133ed5a775dcdf"
          }
        },
        "feae9b4ef96e443cb168441155363e79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f192e7b7cc94ca49f094b91b3d5211d",
            "placeholder": "​",
            "style": "IPY_MODEL_6eb69ece776540ec9d11ca44c4d6e777",
            "value": "Export report to file: 100%"
          }
        },
        "43937867ade64762b429e685acb56cca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_077aeb90900e4ee79c799eab7574e866",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_79807958c0a141538a293559b8655d2b",
            "value": 1
          }
        },
        "c1f0742677a2454286bbde4f5880a18e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ea583c5fdb147c9bde0b01e8038c97b",
            "placeholder": "​",
            "style": "IPY_MODEL_7a3f4c5907f94663be2afaeaf1c8aeeb",
            "value": " 1/1 [00:00&lt;00:00, 36.49it/s]"
          }
        },
        "5a67f0ba31b0452d91133ed5a775dcdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f192e7b7cc94ca49f094b91b3d5211d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6eb69ece776540ec9d11ca44c4d6e777": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "077aeb90900e4ee79c799eab7574e866": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79807958c0a141538a293559b8655d2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4ea583c5fdb147c9bde0b01e8038c97b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a3f4c5907f94663be2afaeaf1c8aeeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}